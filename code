# the packeges we will use
import pandas as pd
import numpy as np
import requests
import sklearn
from bs4 import BeautifulSoup 
base_url_page = "https://www.the-numbers.com/movies/year/" # after the 'year/' part in the url we add the year number

# transfer the data set to numeric values base the the amount of uniwue values in each collom
def transfer_str_to_numeric_vals(dataset):
    df_dataset = dataset.copy()
    for col in df_dataset.columns:
       if col != "profit":
        col_values = df_dataset[col].unique()
        col_values = np.sort(col_values)
        col_number = range(len((df_dataset[col].unique())))
        replace_dict = dict(zip(col_values,col_number))
        df_dataset[col].replace(replace_dict,inplace = True)
    df_dataset = df_dataset.apply(pd.to_numeric)
    return  df_dataset 
    
    def load_soup_object(branches_url):
    response = requests.get(branches_url)
    soup = BeautifulSoup(response.content, 'html.parser')
    return soup
    
    #return a numeric value as string
def turn_num_to_string(number):
    string_num = str(number)
    return string_num
    
    #first we crwaling used to get the url/name/year/profit of each moive as a list each
def scrape_movie_name_url_profit_by_year(soup,year):
   mov_urls = []
   mov_names = []
   mov_year = []
   mov_profit = []
   all_movie = soup.select('b')
   for move in all_movie:
     if move.find("a")["href"] == "https://www.nashinfoservices.com":
        break
     cur_mov_name = move.text
     mov_names.append(cur_mov_name)
     cur_mov_url = "https://www.the-numbers.com/"+move.find("a")["href"]
     mov_urls.append(cur_mov_url)
     mov_year.append(year)
   all_profit = soup.select('td.data')
   for profit in all_profit:
     cur_mov_profit = profit.text
     cur_mov_profit = cur_mov_profit.replace('$', '')
     cur_mov_profit = cur_mov_profit.replace(',', '')
     mov_profit.append(cur_mov_profit)
   return mov_urls, mov_names, mov_year ,mov_profit
   
   #returns the url for the page that conteins the info of the ,oive of the given year
def get_year_url(year):
    cur_url_page = base_url_page+turn_num_to_string(year)
    return cur_url_page
    
    #returns the properties for the movie that is in the givin soup and the properties is missing return a " " for that value
def scrape_movie_properties(soup):
   mov_genre = " "
   mov_prod_met = " "
   mov_run_time = " "
   mov_Lang = " "
   mov_Countrie = " "
   mov_MPAA_rat = " "
   mov_genre_check = 0
   mov_prod_met_check = 0
   mov_run_time_check = 0
   mov_Lang_check = 0
   mov_Countrie_check = 0
   mov_MPAA_rat_check = 0  
   all_movie = soup.select('td')
   for move in all_movie:
     if mov_genre_check == 1:
        mov_genre = move.text
        mov_genre_check = 0
     if move.text == "Genre:":
        mov_genre_check = 1
        
     if mov_prod_met_check == 1:
        mov_prod_met = move.text
        mov_prod_met_check = 0
     if "Method:" in move.text:
        mov_prod_met_check = 1
        
     if mov_run_time_check == 1:
        mov_run_time = move.text
        mov_run_time_check = 0
     if move.text == "Running Time:":
        mov_run_time_check = 1
        
     if mov_Lang_check == 1:
        mov_Lang = move.text
        mov_Lang_check = 0
     if move.text == "Languages:":
        mov_Lang_check = 1   
        
     if mov_Countrie_check == 1:
        mov_Countrie = move.text
        mov_Countrie_check = 0
     if move.text == "Production Countries:":
        mov_Countrie_check = 1     
        
     if mov_MPAA_rat_check == 1:
        mov_MPAA_rat = move.find('a').contents[0]
        mov_MPAA_rat_check = 0
     if "MPAA" in move.text:
        mov_MPAA_rat_check = 1      
        

   return mov_genre, mov_prod_met, mov_run_time, mov_Lang, mov_Countrie, mov_MPAA_rat

#deals with the mising values in the data set in some i give the must common occurrence as a fill in value
def change_missing_values(df):
    df_copy = df.copy(deep=True)
    cur_row = 0
    for row_num in range (df_copy.tail(1).index.item()+1):
         if df_copy.at[row_num,'MPAA Rating'] == " ":
                df_copy.at[row_num,'MPAA Rating'] = "Not Rated"
                
         if df_copy.at[row_num,'Running Time'] == " ":
                df_copy.at[row_num,'Running Time'] = "90"
         df_copy.at[row_num,'Running Time'] = df_copy.at[row_num,'Running Time'].replace(" minutes","")
        
         if df_copy.at[row_num,'Production Countries'] == " ":
                df_copy.at[row_num,'Production Countries'] = "United States"
                
         if df_copy.at[row_num,'Production Method'] == " ":
                df_copy.at[row_num,'Production Method'] = "Live Action"
         if df_copy.at[row_num,'Production Method'] == "Animation/Live Action":
                df_copy.at[row_num,'Production Method'] = "Multiple Production Methods"
                
         if df_copy.at[row_num,'Genre'] == " ":
                df_copy.at[row_num,'Genre'] = "no Genre"       
                
         if df_copy.at[row_num,'Languages'] == " ":
                same_Countries =  df_copy.loc[df['Production Countries'] == df_copy.at[row_num,'Production Countries']]
                df_copy.at[row_num,'Languages'] = same_Countries['Languages'].value_counts().idxmax()
                if df_copy.at[row_num,'Languages'] == " ":
                    df_copy.at[row_num,'Languages'] = "none"           
    return df_copy
    
    from sklearn.model_selection import train_test_split
def split_to_train_and_test(dataset, label_column, test_ratio, rand_state):
    X = dataset.copy()
    y = X[label_column]
    X = X.drop(label_column, axis=1)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test_ratio, random_state= rand_state)
    return X_train, X_test, y_train, y_test
    
    from sklearn import linear_model
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
def train_model(X_train, y_train):
    trained_model=linear_model.LinearRegression().fit(X_train,y_train)
    
    return trained_model
    
    def predict(trained_model, X_test):
    predicted_vals = trained_model.predict(X_test)
    
    return predicted_vals
    
    def evaluate_performance(y_test,y_predicted):
    evaluate_value = r2_score(y_test,y_predicted)
    return evaluate_value
    
    from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
from sklearn.metrics import make_scorer
from sklearn.model_selection import GridSearchCV
def find_best_k_for_KNN(X_train, y_train):
    parameters = {'n_neighbors': [3,5,7,9] }
    knn = KNeighborsClassifier()
    f1 = make_scorer(metrics.f1_score)
    clf = GridSearchCV(knn, parameters,scoring=f1)
    clf.fit(X_train, y_train)
    return clf.best_params_['n_neighbors'], clf.best_score_
    
    
    def get_KNN_obj(params):
    clf = KNeighborsClassifier(n_neighbors=params['n_neighbors'])
    return clf
    
year = 2021 #this is the start year 
mov_urls = []
mov_names = []
mov_year = []
mov_profit = []
for i in range(3):   #this range determines the amount of years we go througe 
  cur_url_page = get_year_url(year - i)
  soup = load_soup_object(cur_url_page)
  cur_mov_urls ,cur_mov_names ,cur_mov_year ,cur_mov_profit = scrape_movie_name_url_profit_by_year(soup, year)
  mov_urls.extend(cur_mov_urls)
  mov_names.extend(cur_mov_names)
  mov_year.extend(cur_mov_year)
  mov_profit.extend(cur_mov_profit)
  
newdict = {'url': mov_urls, 'name': mov_names, 'year': mov_year, 'profit': mov_profit} 
    
df = pd.DataFrame(newdict) #creating the datafream
df = df[df.profit != "0"] #deling with unwanted rows
df

mov_genre = []
mov_prod_met = []
mov_run_time = []
mov_Lang = []
mov_Countrie = []
mov_MPAA_rat = []
count = 1
for cur_url in df.url:
   print(count)
   count = count + 1
   movie_soup = load_soup_object(cur_url)
   cur_mov_genre ,cur_mov_prod_met ,cur_mov_run_time ,cur_mov_Lang ,cur_mov_Countrie ,cur_mov_MPAA_rat = scrape_movie_properties(movie_soup)
   mov_genre.append(cur_mov_genre)
   mov_prod_met.append(cur_mov_prod_met)
   mov_run_time.append(cur_mov_run_time)
   mov_Lang.append(cur_mov_Lang)
   mov_Countrie.append(cur_mov_Countrie)
   mov_MPAA_rat.append(cur_mov_MPAA_rat)
   
df['Languages'] = mov_Lang
df['Production Method'] = mov_prod_met
df['Running Time'] = mov_run_time
df['Production Countries'] = mov_Countrie
df['MPAA Rating'] = mov_MPAA_rat
df['Genre'] = mov_genre

df['MPAA Rating'].value_counts()

df.to_csv('movies.csv')

new_df = pd.read_csv("movies.csv")
new_df = new_df.reset_index(drop=True)
new_df = change_missing_values(new_df)

new_df = new_df.drop(['Unnamed: 0'], axis=1)
new_df

new_df.info()

import seaborn as sns
from matplotlib import pyplot as plt
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
new_df["MPAA Rating"].describe()
new_df["MPAA Rating"].value_counts()
new_df["MPAA Rating"].value_counts().plot(kind='bar')
plt.title('MPAA Rating')

new_df["MPAA Rating"].value_counts().plot(kind='bar')
plt.title('MPAA Rating')

new_df = new_df.drop(['url', 'name'], axis=1)
new_df = transfer_str_to_numeric_vals(new_df)

new_df

test_ratio, rand_state = 0.3, 1000
catagory_col_name = 'profit'
X_train, X_test, y_train, y_test = split_to_train_and_test(new_df, catagory_col_name, test_ratio, rand_state)
trained_model = train_model(X_train, y_train)

pred_vals = predict(trained_model, X_test)
y_pred= pd.Series(pred_vals,index=X_test.index)
eval_res = evaluate_performance(y_test, y_pred)
print(eval_res)
